<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Secure FaceID | MediaPipe</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.12.0/dist/tf.min.js"></script>
  <style>
    body { font-family: Arial, sans-serif; text-align: center; padding: 20px; }
    #video, #canvas { width: 640px; height: 480px; border: 1px solid #ccc; }
    .hidden { display: none; }
    .status { margin: 10px; font-weight: bold; }
  </style>
</head>
<body>
  <h2>Secure Face Recognition (MediaPipe)</h2>
  
  <div id="init-screen">
    <input type="text" id="name" placeholder="Your Name" />
    <br><br>
    <button onclick="startEnroll()">:Register Face</button>
    <button onclick="startRecognition()">üîì Login</button>
  </div>

  <div id="camera-screen" class="hidden">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="canvas" width="640" height="480"></canvas>
    <div id="status" class="status">Initializing...</div>
    <button onclick="stopCamera()">‚Üê Back</button>
  </div>

  <script>
    const WORKER_URL = 'https://face-auth-worker.dhimanparas605.workers.dev';
    let stream = null;
    let faceMesh = null;
    let isRunning = false;

    async function initFaceMesh() {
      if (faceMesh) return;
      faceMesh = new FaceMesh({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
      });
      faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true });
    }

    // üëÅÔ∏è Blink detection using MediaPipe landmarks
    function isBlinking(landmarks) {
      // Left eye: 33, 160, 159, 158, 133, 153, 145, 144
      // Right eye: 263, 387, 386, 385, 362, 380, 374, 373
      const leftEAR = computeEAR([
        landmarks[33], landmarks[160], landmarks[159], landmarks[158],
        landmarks[133], landmarks[153], landmarks[145], landmarks[144]
      ]);
      const rightEAR = computeEAR([
        landmarks[263], landmarks[387], landmarks[386], landmarks[385],
        landmarks[362], landmarks[380], landmarks[374], landmarks[373]
      ]);
      const avgEAR = (leftEAR + rightEAR) / 2;
      console.log('EAR:', avgEAR.toFixed(3));
      return avgEAR < 0.25;
    }

    function computeEAR(eye) {
      const A = Math.sqrt(Math.pow(eye[1].x - eye[7].x, 2) + Math.pow(eye[1].y - eye[7].y, 2));
      const B = Math.sqrt(Math.pow(eye[2].x - eye[6].x, 2) + Math.pow(eye[2].y - eye[6].y, 2));
      const C = Math.sqrt(Math.pow(eye[3].x - eye[5].x, 2) + Math.pow(eye[3].y - eye[5].y, 2));
      const D = Math.sqrt(Math.pow(eye[0].x - eye[4].x, 2) + Math.pow(eye[0].y - eye[4].y, 2));
      return (A + B + C) / (3.0 * D);
    }

    async function startCamera() {
      await initFaceMesh();
      stream = await navigator.mediaDevices.getUserMedia({ video: true });
      document.getElementById('video').srcObject = stream;
      document.getElementById('init-screen').classList.add('hidden');
      document.getElementById('camera-screen').classList.remove('hidden');
      isRunning = true;
      processVideo();
    }

    function stopCamera() {
      isRunning = false;
      if (stream) stream.getTracks().forEach(t => t.stop());
      document.getElementById('camera-screen').classList.add('hidden');
      document.getElementById('init-screen').classList.remove('hidden');
    }

    async function processVideo() {
      if (!isRunning) return;
      
      const video = document.getElementById('video');
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');

      if (video.readyState === video.HAVE_ENOUGH_DATA) {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        
        const predictions = await faceMesh.send({ image: video });
        if (predictions.length > 0) {
          const landmarks = predictions[0].landmarks;
          
          // Draw face mesh
          ctx.strokeStyle = '#4361ee';
          ctx.lineWidth = 2;
          ctx.beginPath();
          for (let i = 0; i < landmarks.length; i++) {
            const x = landmarks[i].x * canvas.width;
            const y = landmarks[i].y * canvas.height;
            if (i === 0) ctx.moveTo(x, y);
            else ctx.lineTo(x, y);
          }
          ctx.stroke();

          // Blink detection
          if (isBlinking(landmarks)) {
            document.getElementById('status').textContent = '‚úÖ Blink detected!';
            document.getElementById('status').style.color = 'green';
            // You can now capture frame for recognition
          } else {
            document.getElementById('status').textContent = 'üëÄ Look and blink';
            document.getElementById('status').style.color = 'gray';
          }
        } else {
          document.getElementById('status').textContent = 'No face';
        }
      }

      requestAnimationFrame(processVideo);
    }

    async function startEnroll() {
      const name = document.getElementById('name').value.trim();
      if (!name) return alert('Enter name');
      await startCamera();
      // Add enrollment logic here
    }

    async function startRecognition() {
      await startCamera();
      // Add recognition logic here
    }

    console.log('Ready to use MediaPipe!');
  </script>
</body>
</html>
