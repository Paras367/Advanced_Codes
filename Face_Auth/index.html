<!--BY PARAS-->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>BHARAT FaceID | MediaPipe</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.12.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh@0.1.3/dist/facemesh.min.js"></script>
  <style>
    :root {
      --primary: #4361ee;
      --success: #06d6a0;
      --danger: #ef476f;
      --dark: #1d3557;
    }
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: linear-gradient(135deg, #f5f7fa 0%, #e4edf9 100%);
      color: var(--dark);
      margin: 0;
      padding: 20px;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      text-align: center;
    }
    h1 {
      color: var(--primary);
      margin-bottom: 20px;
    }
    .card {
      background: white;
      border-radius: 16px;
      padding: 20px;
      box-shadow: 0 4px 20px rgba(0,0,0,0.1);
      margin: 20px 0;
    }
    input, button {
      padding: 12px;
      margin: 10px;
      border-radius: 8px;
      border: 1px solid #ddd;
      font-size: 16px;
    }
    button {
      background: var(--primary);
      color: white;
      border: none;
      cursor: pointer;
      transition: background 0.3s;
    }
    button:hover {
      background: #3a56d4;
    }
    button.success {
      background: var(--success);
    }
    #video, #canvas {
      width: 100%;
      max-width: 640px;
      height: auto;
      border-radius: 12px;
      display: block;
      margin: 10px auto;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
      z-index: 10;
    }
    #status {
      font-weight: bold;
      margin: 10px 0;
      min-height: 1.5em;
    }
    .hidden { display: none; }
  </style>
</head>
<body>
  <div class="container">
    <h1>üîê BHARAT FaceID</h1>
    
    <div id="init-screen">
      <div class="card">
        <input type="text" id="nameInput" placeholder="Your Full Name" autocomplete="name" />
        <br>
        <button onclick="startEnroll()">:Register Face</button>
        <button class="success" onclick="startRecognition()">üîì Face Login</button>
      </div>
    </div>

    <div id="camera-screen" class="hidden">
      <div style="position: relative; display: inline-block;">
        <video id="video" autoplay muted playsinline></video>
        <canvas id="canvas" width="640" height="480"></canvas>
      </div>
      <div id="status">Initializing...</div>
      <button onclick="stopCamera()">‚Üê Back</button>
    </div>
  </div>

  <script>
    const WORKER_URL = 'https://face-auth-worker.dhimanparas605.workers.dev';
    let stream = null;
    let faceMesh = null;
    let isRunning = false;
    let lastDescriptor = null;

    // Initialize MediaPipe FaceMesh
    async function initFaceMesh() {
      if (faceMesh) return;
      faceMesh = new FaceMesh({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
      });
      faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true });
    }

    // Blink detection using MediaPipe landmarks
    function isBlinking(landmarks) {
      // Left eye indices: 33, 160, 159, 158, 133, 153, 145, 144
      // Right eye indices: 263, 387, 386, 385, 362, 380, 374, 373
      const leftEAR = computeEAR([
        landmarks[33], landmarks[160], landmarks[159], landmarks[158],
        landmarks[133], landmarks[153], landmarks[145], landmarks[144]
      ]);
      const rightEAR = computeEAR([
        landmarks[263], landmarks[387], landmarks[386], landmarks[385],
        landmarks[362], landmarks[380], landmarks[374], landmarks[373]
      ]);
      const avgEAR = (leftEAR + rightEAR) / 2;
      console.log('EAR:', avgEAR.toFixed(3));
      return avgEAR < 0.25;
    }

    function computeEAR(eye) {
      const A = Math.sqrt(Math.pow(eye[1].x - eye[7].x, 2) + Math.pow(eye[1].y - eye[7].y, 2));
      const B = Math.sqrt(Math.pow(eye[2].x - eye[6].x, 2) + Math.pow(eye[2].y - eye[6].y, 2));
      const C = Math.sqrt(Math.pow(eye[3].x - eye[5].x, 2) + Math.pow(eye[3].y - eye[5].y, 2));
      const D = Math.sqrt(Math.pow(eye[0].x - eye[4].x, 2) + Math.pow(eye[0].y - eye[4].y, 2));
      return (A + B + C) / (3.0 * D);
    }

    // Generate face descriptor using simple hash of landmarks
    function generateDescriptor(landmarks) {
      // In production, use a proper face embedding model
      // For now, use a stable hash of key points
      let hash = 0;
      for (let i = 0; i < landmarks.length; i += 10) {
        const x = Math.round(landmarks[i].x * 1000);
        const y = Math.round(landmarks[i].y * 1000);
        hash = ((hash << 5) - hash) + x + y;
      }
      return Array(128).fill(0).map((_, i) => (hash + i) % 100 / 100);
    }

    async function startCamera() {
      await initFaceMesh();
      stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
      document.getElementById('video').srcObject = stream;
      document.getElementById('init-screen').classList.add('hidden');
      document.getElementById('camera-screen').classList.remove('hidden');
      isRunning = true;
      processVideo();
    }

    function stopCamera() {
      isRunning = false;
      if (stream) stream.getTracks().forEach(t => t.stop());
      document.getElementById('camera-screen').classList.add('hidden');
      document.getElementById('init-screen').classList.remove('hidden');
    }

    async function processVideo() {
      if (!isRunning) return;
      
      const video = document.getElementById('video');
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');

      if (video.readyState === video.HAVE_ENOUGH_DATA) {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        
        const predictions = await faceMesh.send({ image: video });
        if (predictions.length > 0) {
          const landmarks = predictions[0].landmarks;
          
          // Draw face mesh
          ctx.strokeStyle = '#4361ee';
          ctx.lineWidth = 1;
          ctx.beginPath();
          for (let i = 0; i < landmarks.length; i++) {
            const x = landmarks[i].x * canvas.width;
            const y = landmarks[i].y * canvas.height;
            if (i === 0) ctx.moveTo(x, y);
            else ctx.lineTo(x, y);
          }
          ctx.stroke();

          // Store descriptor
          lastDescriptor = generateDescriptor(landmarks);

          // Blink detection
          if (isBlinking(landmarks)) {
            document.getElementById('status').textContent = '‚úÖ Blink detected!';
            document.getElementById('status').style.color = 'green';
          } else {
            document.getElementById('status').textContent = 'üëÄ Look at camera and blink';
            document.getElementById('status').style.color = '#6c757d';
          }
        } else {
          lastDescriptor = null;
          document.getElementById('status').textContent = 'No face detected';
        }
      }

      requestAnimationFrame(processVideo);
    }

    // Enrollment
    async function startEnroll() {
      const name = document.getElementById('nameInput').value.trim();
      if (!name) return alert('Please enter your name');
      await startCamera();
      
      // Wait for blink
      const waitForBlink = async () => {
        if (!isRunning) return;
        if (lastDescriptor && isBlinking(lastDescriptor.map(p => ({x: p, y: p})))) {
          // This is simplified - in reality, you'd capture at blink moment
          try {
            const res = await fetch(`${WORKER_URL}/enroll`, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ name, descriptor: lastDescriptor })
            });
            const data = await res.json();
            alert(data.success ? `${name}, enrolled!` : 'Failed');
          } catch (e) {
            alert('Network error');
          }
          setTimeout(stopCamera, 2000);
          return;
        }
        setTimeout(waitForBlink, 300);
      };
      
      setTimeout(waitForBlink, 1000);
    }

    // Recognition
    async function startRecognition() {
      await startCamera();
      
      const waitForBlink = async () => {
        if (!isRunning) return;
        if (lastDescriptor && isBlinking(lastDescriptor.map(p => ({x: p, y: p})))) {
          try {
            const res = await fetch(`${WORKER_URL}/descriptors`);
            const users = await res.json();
            let match = null;
            for (const u of users) {
              const dist = euclideanDistance(lastDescriptor, u.descriptor);
              if (dist < 0.6) {
                match = u.name;
                break;
              }
            }
            if (match) {
              await fetch(`${WORKER_URL}/attendance`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ name: match })
              });
              alert(`Welcome, ${match}!`);
            } else {
              alert('Not recognized');
            }
          } catch (e) {
            alert('Error');
          }
          setTimeout(stopCamera, 2000);
          return;
        }
        setTimeout(waitForBlink, 300);
      };
      
      setTimeout(waitForBlink, 1000);
    }

    function euclideanDistance(a, b) {
      let sum = 0;
      for (let i = 0; i < a.length; i++) {
        sum += Math.pow(a[i] - b[i], 2);
      }
      return Math.sqrt(sum);
    }

    console.log('System ready!');
  </script>
</body>
</html>
